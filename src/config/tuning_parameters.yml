alg: dqn
bootstrap_count: 0
env: pendulum
eval_freq: 10000
frame_stack: null
git_link: github.com/karolisw/hyperFetch
hyperparameters:
  batch_size: 256
  buffer_size: 50000
  exploration_final_eps: 0.10717928118310233
  exploration_fraction: 0.3318973226098944
  gamma: 0.9
  learning_rate: 0.0002126832542803243
  learning_starts: 10000
  net_arch: medium
  subsample_steps: 4
  target_update_interval: 1000
  train_freq: 8
log_folder: logs
lower: 0.0
max_resource: 6
min_delta: 0.05
min_resource: 4
n_envs: 1
n_evaluations: 5
n_jobs: 1
n_min_trials: 1
n_startup_trials: 5
n_timesteps: 20000
n_trials: 10
n_warmup_steps: 0
patience: 50
percentile: 25.0
policy: MlpPolicy
post_run: true
project_name: HyperFetch
pruner: median
reduction_factor: 3.0
reward_threshold: null
sampler: tpe
seed: 1
trial_log_path: logs/trials
upper: 1.0
